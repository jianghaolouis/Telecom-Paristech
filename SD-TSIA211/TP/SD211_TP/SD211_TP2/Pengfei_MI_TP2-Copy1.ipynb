{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Partie-1:-Régularisation-de-Tikhonov\" data-toc-modified-id=\"Partie-1:-Régularisation-de-Tikhonov-1\">Partie 1: Régularisation de Tikhonov</a></span></li><li><span><a href=\"#Partie-2:-Régularisation-pour-la-parcimoine\" data-toc-modified-id=\"Partie-2:-Régularisation-pour-la-parcimoine-2\">Partie 2: Régularisation pour la parcimoine</a></span></li><li><span><a href=\"#Partie-3:-Comparaison\" data-toc-modified-id=\"Partie-3:-Comparaison-3\">Partie 3: Comparaison</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SD211 TP2: Régression logistique\n",
    "*<p>Author: Pengfei Mi</p>*\n",
    "*<p>Date: 12/05/2017</p>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cervicalcancerutils import load_cervical_cancer\n",
    "from scipy.optimize import check_grad\n",
    "from time import time\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1: Régularisation de Tikhonov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Question 1.1}\\quad\\text{Calculer le gradient et la matrice hessienne.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p>\n",
    "        Notons $\\tilde{X} = (\\tilde{\\mathbf{x}}_1,...,\\tilde{\\mathbf{ x}}_n)^T$, où $\\tilde{\\mathbf{x}}_i = \\begin{pmatrix}1\\\\ \n",
    "        \\mathbf{x}_i\\end{pmatrix}\\in \\mathbb{R}^{p+1}$, $\\tilde{\\mathbf{\\omega}} = \\begin{pmatrix}\n",
    "        \\omega_0\\\\\\mathbf{\\omega}\\end{pmatrix}\\in \\mathbb{R}^{p+1}$, et la matrice\n",
    "        $$A = diag(0,1,...,1) =\n",
    "        \\begin{pmatrix}\n",
    "        0&0&\\cdots&0\\\\\n",
    "        0&1&&0\\\\\n",
    "        \\vdots&&\\ddots&\\vdots\\\\\n",
    "        0&0&\\cdots&1\n",
    "        \\end{pmatrix}\n",
    "        $$\n",
    "    </p>\n",
    "    <p>\n",
    "        On a:\n",
    "        $$\n",
    "        \\begin{aligned}\n",
    "        f_1(\\omega_0, \\omega) &= \\frac{1}{n}\\sum_{i=1}^{n}\\text{log}\\big(1+e^{-y_i(x_i^T\\omega+\\omega_0)}\\big)+\\frac{\\rho}{2}\\|\\omega\\|_2^2 \\\\\n",
    "        & = \\frac{1}{n}\\sum_{i=1}^{n}\\text{log}\\big(1+e^{-y_i\\tilde x_i^T \\tilde \\omega}\\big)+\\frac{\\rho}{2}\\tilde{\\omega}^TA\\tilde{\\omega}\n",
    "        \\end{aligned}\n",
    "        $$\n",
    "    </p>\n",
    "    <p>\n",
    "        Ainsi on obtient le gradient:\n",
    "        $$\n",
    "        \\begin{aligned}\n",
    "        \\nabla{f_1}(\\omega_0, \\omega) &= \\frac{1}{n}\\sum_{i=1}^{n}\\frac{-e^{-y_i\\tilde x_i^T \\tilde \\omega}y_i\\tilde{\\mathbf{x}}_i}{1+e^{-y_i\\tilde x_i^T \\tilde \\omega}} + \\rho A\\tilde{\\mathbf{\\omega}} \\\\\n",
    "        &= \\frac{1}{n}\\sum_{i=1}^{n}\\frac{-y_i\\tilde{\\mathbf{x}}_i}{1+e^{y_i\\tilde x_i^T \\tilde \\omega}} + \n",
    "        \\rho A\\tilde{\\mathbf{\\omega}}\n",
    "        \\end{aligned}\n",
    "        $$\n",
    "    </p>\n",
    "    <p>\n",
    "        et la matrice hessienne:\n",
    "        $$\n",
    "        \\begin{aligned}\n",
    "        \\mathbf{H} = \\nabla^2f_1(\\omega_0, \\omega) &= \\frac{1}{n}\\sum_{i=1}^{n}\\frac{e^{y_i\\tilde x_i^T \\tilde \\omega}(y_i\\tilde{\\mathbf{x}}_i)(y_i\\tilde{\\mathbf{x}}_i)^T}{(1+e^{y_i\\tilde x_i^T \\tilde \\omega})^2} + \\rho A \\\\\n",
    "        & = \\frac{1}{n}\\sum_{i=1}^{n}\\frac{(y_i\\tilde{\\mathbf{x}}_i)(y_i\\tilde{\\mathbf{x}}_i)^T}{(1+e^{y_i\\tilde x_i^T \\tilde \\omega})(1+e^{-y_i\\tilde x_i^T \\tilde \\omega})} + \\rho A\n",
    "        \\end{aligned}\n",
    "        $$\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <p>\n",
    "        Soient $\\omega \\in \\mathbb{R}^{p+1}$, on a:\n",
    "        $$\n",
    "        \\begin{aligned}\n",
    "        \\omega^TH\\omega &= \\frac{1}{n}\\sum_{i=1}^{n}\\frac{\\omega^T (y_i\\tilde{\\mathbf{x}}_i)(y_i\\tilde{\\mathbf{x}}_i)^T \\omega}{(1+e^{y_i\\tilde x_i^T \\tilde \\omega})(1+e^{-y_i\\tilde x_i^T \\tilde \\omega})} + \\rho \\omega^T A \\omega \\\\\n",
    "        &= \\frac{1}{n}\\sum_{i=1}^{n}\\frac{(\\omega^T y_i\\tilde{\\mathbf{x}}_i)(\\omega^T y_i\\tilde{\\mathbf{x}}_i)^T}{(1+e^{y_i\\tilde x_i^T \\tilde \\omega})(1+e^{-y_i\\tilde x_i^T \\tilde \\omega})} + \\rho \\omega^T A^2 \\omega \\\\\n",
    "        &= \\frac{1}{n}\\sum_{i=1}^{n}\\frac{\\|\\omega^T y_i\\tilde{\\mathbf{x}}_i\\|_2^2}{(1+e^{y_i\\tilde x_i^T \\tilde \\omega})(1+e^{-y_i\\tilde x_i^T \\tilde \\omega})} + \\rho \\|A\\omega\\|_2^2 \\geq 0\n",
    "        \\end{aligned}\n",
    "        $$\n",
    "    </p>\n",
    "    <p>Donc, la matrice hessienne est semi-définie positive, la fonction $f_1$ est convexe.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Question 1.2}\\quad\\text{Coder une fonction qui retourne la valeur de la fonction, son gradient et sa hessienne.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p>On insère une colonne de $1$ à gauche de $X$ pour simplifier le calcul.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before the insertion:\n",
      "(210, 26) (210,)\n",
      "After the insertion:\n",
      "(210, 27) (210,)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_cervical_cancer(\"riskfactorscervicalcancer.csv\")\n",
    "print \"Before the insertion:\"\n",
    "print X.shape, y.shape\n",
    "n, p = X.shape\n",
    "X = np.c_[np.ones(n), X]\n",
    "print \"After the insertion:\"\n",
    "print X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(w_, X, y, rho, return_grad=True, return_H=True):\n",
    "    \"\"\"\n",
    "    X: matrix of size n*(p+1)\n",
    "    y: vector of size n\n",
    "    w0: real number\n",
    "    w: vector of size p\n",
    "    \"\"\"\n",
    "    # Initialize elementary intermediate variables;\n",
    "    n, p = X.shape\n",
    "    w = w_[1:]\n",
    "    y_x = np.array([y[i] * X[i, :] for i in range(n)])\n",
    "    yx_w = np.array([np.sum(y_x[i, :]*w_) for i in range(n)])\n",
    "    exp_yxw_1 = np.array([np.exp(yx_w[i]) for i in range(n)]) + 1\n",
    "    exp_neg_yxw_1 = np.array([np.exp(-yx_w[i]) for i in range(n)]) + 1\n",
    "    \n",
    "    # Compute function value\n",
    "    val = np.mean(np.log(exp_neg_yxw_1)) + np.sum(w**2)*rho/2.\n",
    "    \n",
    "    if return_grad == False:\n",
    "        return val\n",
    "    else:\n",
    "        # Compute gradient\n",
    "        grad = np.mean(-np.array([y_x[i]/exp_yxw_1[i] for i in range(n)]), axis=0) + rho*np.r_[0, w]\n",
    "        \n",
    "        if return_H == False:\n",
    "            return val, grad\n",
    "        else:\n",
    "            # Compute the Hessian matrix\n",
    "            H = np.mean(np.array([y_x[i].reshape(-1, 1).dot(y_x[i].reshape(1, -1) / (exp_yxw_1[i]*exp_neg_yxw_1[i])) for i in range(n)]), axis=0) + rho*np.diag(np.r_[0, np.ones(p-1)])\n",
    "            return val, grad, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference of gradient is: 0.000000039161\n",
      "Done in 0.073s.\n"
     ]
    }
   ],
   "source": [
    "def funcMask(w_, X, y, rho):\n",
    "    val, grad = objective(w_, X, y, rho, return_H=False)\n",
    "    return val\n",
    "\n",
    "def gradMask(w_, X, y, rho):\n",
    "    val, grad = objective(w_, X, y, rho, return_H=False)\n",
    "    return grad\n",
    "\n",
    "rho = 1./n\n",
    "t0 = time()\n",
    "print \"The difference of gradient is: %0.12f\" % check_grad(funcMask, gradMask, np.zeros(p+1), X, y, rho)\n",
    "print \"Done in %0.3fs.\" % (time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference of Hessian matrix is: 0.000000758053\n",
      "Done in 0.079s.\n"
     ]
    }
   ],
   "source": [
    "def gradMask(w_, X, y, rho):\n",
    "    val, grad = objective(w_, X, y, rho, return_H=False)\n",
    "    return grad.sum()\n",
    "\n",
    "def hessianMask(w_, X, y, rho):\n",
    "    val, grad, H = objective(w_, X, y, rho)\n",
    "    return np.sum(H, axis=1)\n",
    "\n",
    "t0 = time()\n",
    "rho = 1./n\n",
    "print \"The difference of Hessian matrix is: %0.12f\" % check_grad(gradMask, hessianMask, np.zeros(p+1), X, y, rho)\n",
    "print \"Done in %0.3fs.\" % (time()-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p>On a vérifié le calcul de gradient et de matrice hessienne.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Question 1.3}\\quad\\text{Coder la méthode de Newton.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p>\n",
    "        Selon la définition de méthode de Newton, on a:\n",
    "        $$\\omega^{k+1} = \\omega^k - (\\nabla^2f_1(\\omega^k))^{-1}\\nabla f_1(\\omega^k)$$\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value minimal of the objective function is: 0.564490766022\n",
      "Done in 0.043s, number of iterations: 7\n",
      "[ 0.2013495  -0.17213872 -0.04798368 -0.14852973  0.17226181 -0.00720006\n",
      "  0.20673756 -0.03692106  0.0768277   0.43086559  0.12956021  0.17260728\n",
      "  0.31592059  0.17684201  0.10474188  0.10474188 -0.39105042  0.1639398\n",
      "  0.66262584 -0.33199982  0.64063084 -0.39451384 -0.39515206  0.3884854\n",
      "  0.02848865  0.3884854   0.27776305]\n"
     ]
    }
   ],
   "source": [
    "def minimize_Newton(func, w_, X, y, rho, tol=1e-10):\n",
    "    n, p = X.shape\n",
    "    val, grad, H = func(w_, X, y, rho)\n",
    "    grad_norm = np.sqrt(np.sum(grad**2))\n",
    "    norms = [grad_norm]\n",
    "    cnt = 0\n",
    "    while (grad_norm > tol):\n",
    "        w_ = w_ - np.linalg.solve(H, np.identity(p)).dot(grad)\n",
    "        val, grad, H = func(w_, X, y, rho)\n",
    "        grad_norm = np.sqrt(np.sum(grad**2))\n",
    "        norms.append(grad_norm)\n",
    "        cnt = cnt + 1\n",
    "    return val, w_, cnt, norms\n",
    "\n",
    "t0 = time()\n",
    "rho = 1./n\n",
    "val, w, cnt, grad_norms  = minimize_Newton(objective, np.zeros(p+1), X, y, rho, tol=1e-10)\n",
    "print \"The value minimal of the objective function is: %0.12f\" % val\n",
    "print \"Done in %0.3fs, number of iterations: %d\" % (time()-t0, cnt)\n",
    "print w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgIAAAGHCAYAAADC0Do6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA7YjEm2g6o6TAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114f6a790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize=(8,6))\n",
    "plt.title(\"The norm of gradient, $\\omega^0 = 0$\")\n",
    "plt.semilogy(range(0, len(grad_norms)), grad_norms)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Norm of gradient\")\n",
    "plt.xlim(0, len(grad_norms))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Question 1.4}\\quad\\text{Lancer avec comme condition initiale }(\\omega_0^0,\\omega^0) = 0.3e\\text{, où }e_i=0\\text{ pour tout }i.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:13: RuntimeWarning: overflow encountered in exp\n",
      "/Applications/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:14: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-26abe0144c22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norms\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mminimize_Newton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"The value minimal of the objective function is: %0.12f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Done in %0.3fs, number of iterations: %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-bc7ce3bd5ceb>\u001b[0m in \u001b[0;36mminimize_Newton\u001b[0;34m(func, w_, X, y, rho, tol)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrad_norm\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mw_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/numpy/linalg/linalg.pyc\u001b[0m in \u001b[0;36msolve\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'DD->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'dd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/numpy/linalg/linalg.pyc\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "val, grad, H, cnt, grad_norms  = minimize_Newton(objective, 0.3*np.ones(p+1), X, y, rho, tol=1e-10)\n",
    "print \"The value minimal of the objective function is: %0.12f\" % val\n",
    "print \"Done in %0.3fs, number of iterations: %d\" % (time()-t0, cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p>On a vu que avec cette condition initiale, la fonction objectif ne converge pas. C'est à cause de le point initiale est hors le domaine de convergence.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Question 1.5}\\quad\\text{Coder la méthode de recherche linéaire d'Armijo.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p>Notons $\\omega^+(\\gamma_k)=\\omega^k - \\gamma_k(\\nabla^2 f_1(\\omega^k))^{-1}\\nabla f_1(\\omega^k)$, soient $a \\in (0,1)$, $b>0$ et $\\beta \\in (0,1)$, on cherche le premier entier $l$ non-négatif tel que:</p>\n",
    "    $$f_1(\\omega^+(ba^l)) \\leq f_1(\\omega^k) + \\beta\\langle\\nabla_{f_1}(\\omega^k),\\,\\omega^+(ba^l)-\\omega^k\\rangle$$\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <p>Ici, on prend $\\beta = 0.5$, ainsi que la recherche linéaire d'Armijo devient équicalente à la recherche linéaire de Taylor.</p>\n",
    "    <p> On fixe $b_0 = 1$ et $b_k = 2\\gamma_{k-1}$, c'est un choix classique.</p>\n",
    "    <p> On fixe $a = 0.5$, c'est pour faire un compromis entre la précision de recherche et la vitesse de convergence.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value minimal of the objective function is: 0.564490766022\n",
      "Done in 0.082s, number of iterations: 9\n",
      "[ 0.2013495  -0.17213872 -0.04798368 -0.14852973  0.17226181 -0.00720006\n",
      "  0.20673756 -0.03692106  0.0768277   0.43086559  0.12956021  0.17260728\n",
      "  0.31592059  0.17684201  0.10474188  0.10474188 -0.39105042  0.1639398\n",
      "  0.66262584 -0.33199982  0.64063084 -0.39451384 -0.39515206  0.3884854\n",
      "  0.02848865  0.3884854   0.27776305]\n"
     ]
    }
   ],
   "source": [
    "def minimize_Newton_Armijo(func, w_, X, y, rho, a, b, beta, tol=1e-10, max_iter=500):\n",
    "    n, p = X.shape\n",
    "    val, grad, H = func(w_, X, y, rho)\n",
    "    grad_norm = np.sqrt(np.sum(grad**2))\n",
    "    norms = [grad_norm]\n",
    "    d = np.linalg.solve(H, np.identity(p)).dot(grad)\n",
    "    gamma = b / 2.\n",
    "    cnt = 0\n",
    "    while (grad_norm > tol and cnt < max_iter):\n",
    "        gamma = 2*gamma\n",
    "        val_ = func(w_ - gamma*d, X, y, rho, return_grad=False)\n",
    "        while (val_ > val - beta*gamma*np.sum(d*grad)):\n",
    "            gamma = gamma*a\n",
    "            val_ = func(w_ - gamma*d, X, y, rho, return_grad=False)\n",
    "        w_ = w_ - gamma*d\n",
    "        val, grad, H = func(w_, X, y, rho)\n",
    "        d = np.linalg.solve(H, np.identity(p)).dot(grad)\n",
    "        grad_norm = np.sqrt(np.sum(grad**2))\n",
    "        norms.append(grad_norm)\n",
    "        cnt = cnt + 1\n",
    "    return val, w_, cnt, norms\n",
    "\n",
    "t0 = time()\n",
    "rho = 1./n\n",
    "a = 0.5\n",
    "b = 1\n",
    "beta = 0.5\n",
    "val_nls, w_nls, cnt_nls, grad_norms_nls  = minimize_Newton_Armijo(objective, 0.3*np.ones(p+1), X, y, rho, a, b, beta, tol=1e-10, max_iter=500)\n",
    "print \"The value minimal of the objective function is: %0.12f\" % val_nls\n",
    "t_nls = time()-t0\n",
    "print \"Done in %0.3fs, number of iterations: %d\" % (t_nls, cnt_nls)\n",
    "print w_nls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgUAAAGDCAYAAAC7nWNVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d560bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(2, figsize=(8,6))\n",
    "plt.title(\"The norm of gradient by Newton with linear search\")\n",
    "plt.semilogy(range(0, len(grad_norms_nls)), grad_norms_nls)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Norm of gradient\")\n",
    "plt.xlim(0, len(grad_norms_nls))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2: Régularisation pour la parcimoine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Question 2.1}\\quad\\text{Pourquoi ne peut-on pas utiliser la méthode de Newton pour résoudre ce problème?}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p>Parce que la fonction objectif ici n'est pas différentiable, on ne peut pas utiliser le gradient et la matrice hessienne.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Question 2.2}\\quad\\text{Écrire la fonction objectif sous la forme }F_2 = f_2 + g_2\\text{ où }f_2\\text{ est dérivable et l’opérateur proximal de }g_2\\text{ est simple.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p>\n",
    "        $$\n",
    "        \\begin{aligned}\n",
    "        F_2(\\omega_0,\\omega) &= \\frac{1}{n}\\sum_{i=1}^{n}\\text{log}\\big(1+e^{-y_i(x_i^T\\omega+\\omega_0)}\\big)+\\rho\\|\\omega\\|_1 \\\\\n",
    "        &= f_2+g_2\n",
    "        \\end{aligned}\n",
    "        $$\n",
    "        où $f_2 = \\frac{1}{n}\\sum_{i=1}^{n}\\text{log}\\big(1+e^{-y_i(x_i^T\\omega+\\omega_0)}\\big)$ est dérivable, $g_2 = \\rho\\|\\omega\\|_1$ de laquelle l'opérateur proximal est simple.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <p>\n",
    "        On a le gradient de $f_2$:\n",
    "        $$\n",
    "        \\begin{aligned}\n",
    "        \\nabla{f_2}(\\omega_0, \\omega) &= \\frac{1}{n}\\sum_{i=1}^{n}\\frac{-e^{-y_i\\tilde x_i^T \\tilde \\omega}y_i\\tilde{\\mathbf{x}}_i}{1+e^{-y_i\\tilde x_i^T \\tilde \\omega}} \\\\\n",
    "        &= \\frac{1}{n}\\sum_{i=1}^{n}\\frac{-y_i\\tilde{\\mathbf{x}}_i}{1+e^{y_i\\tilde x_i^T \\tilde \\omega}}\n",
    "        \\end{aligned}\n",
    "        $$\n",
    "    </p>\n",
    "    <p>\n",
    "        et l'opérateur proximal de $g_2$:\n",
    "        $$\n",
    "        \\begin{aligned}\n",
    "        \\text{prox}_{g_2}(x) &= \\text{arg}\\,\\underset{y \\in \\mathbb{R}^p}{\\text{min}}\\, \\big(g_2(y) + \\frac{1}{2}\\|y-x\\|^2 \\big) \\\\\n",
    "        &= \\text{arg}\\,\\underset{y \\in \\mathbb{R}^p}{\\text{min}}\\, \\big(\\rho\\|y\\|_1 + \\frac{1}{2}\\|y-x\\|^2 \\big) \\\\\n",
    "        &= \\text{arg}\\,\\underset{y \\in \\mathbb{R}^p}{\\text{min}}\\, \\sum_{i=1}^{p}\\big(\\rho |y_i| + \\frac{1}{2}(y_i-x_i)^2\\big)\n",
    "        \\end{aligned}\n",
    "        $$\n",
    "    </p>\n",
    "    <p>\n",
    "    pour $1 \\leq i \\leq n$, on obtient la solution:\n",
    "    $$\n",
    "    y_i^* = \\left\\{\n",
    "    \\begin{align}\n",
    "    x_i - \\rho, &\\text{ si } x_i > \\rho \\\\\n",
    "    x_i + \\rho, &\\text{ si } x_i < -\\rho \\\\\n",
    "    0, &\\text{ si } -\\rho \\leq x_i \\leq \\rho\n",
    "    \\end{align}\n",
    "    \\right.\n",
    "    $$\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <p>\n",
    "        $$\n",
    "        \\begin{aligned}\n",
    "        \\mathbf{H_2} = \\nabla^2f_2(\\omega_0, \\omega) &= \\frac{1}{n}\\sum_{i=1}^{n}\\frac{e^{y_i\\tilde x_i^T \\tilde \\omega}(y_i\\tilde{\\mathbf{x}}_i)(y_i\\tilde{\\mathbf{x}}_i)^T}{(1+e^{y_i\\tilde x_i^T \\tilde \\omega})^2} \\\\\n",
    "        & = \\frac{1}{n}\\sum_{i=1}^{n}\\frac{(y_i\\tilde{\\mathbf{x}}_i)(y_i\\tilde{\\mathbf{x}}_i)^T}{(1+e^{y_i\\tilde x_i^T \\tilde \\omega})(1+e^{-y_i\\tilde x_i^T \\tilde \\omega})}\n",
    "        \\end{aligned}\n",
    "        $$\n",
    "    </p>\n",
    "    <p>\n",
    "    Soient $\\omega \\in \\mathbb{R}^{p+1}$, on a:\n",
    "        $$\n",
    "        \\begin{aligned}\n",
    "        \\omega^TH_2\\omega &= \\frac{1}{n}\\sum_{i=1}^{n}\\frac{\\omega^T (y_i\\tilde{\\mathbf{x}}_i)(y_i\\tilde{\\mathbf{x}}_i)^T \\omega}{(1+e^{y_i\\tilde x_i^T \\tilde \\omega})(1+e^{-y_i\\tilde x_i^T \\tilde \\omega})} \\\\\n",
    "        &= \\frac{1}{n}\\sum_{i=1}^{n}\\frac{(\\omega^T y_i\\tilde{\\mathbf{x}}_i)(\\omega^T y_i\\tilde{\\mathbf{x}}_i)^T}{(1+e^{y_i\\tilde x_i^T \\tilde \\omega})(1+e^{-y_i\\tilde x_i^T \\tilde \\omega})} \\\\\n",
    "        &= \\frac{1}{n}\\sum_{i=1}^{n}\\frac{\\|\\omega^T y_i\\tilde{\\mathbf{x}}_i\\|_2^2}{(1+e^{y_i\\tilde x_i^T \\tilde \\omega})(1+e^{-y_i\\tilde x_i^T \\tilde \\omega})} \\geq 0\n",
    "        \\end{aligned}\n",
    "        $$\n",
    "    </p>\n",
    "    <p>Donc, la matrice hessienne de $f_2$ est semi-définie positive, la fonction $f_2$ est convexe.</p>\n",
    "    <p>\n",
    "    $$\n",
    "        \\begin{aligned}\n",
    "        g_2(\\omega_0, \\omega) &= \\rho\\|\\omega\\|_1 \\\\\n",
    "        &= \\rho \\sum_{i=1}^{n}|\\omega_i|\n",
    "        \\end{aligned}\n",
    "    $$\n",
    "    </p>\n",
    "    <p>La fonction de valeur absolue est convexe pour chaque élément de $\\omega$, pour $\\rho \\geq 0$, $g_2$ est aussi convexe.</p>\n",
    "    <p>Donc $F_2 = f_2 + g_2$ est convexe pour $\\rho \\geq 0$.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Question 2.3}\\quad\\text{Coder le gradient proximal avec recherche linéaire.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p>On rajoute la recherche linéaire de Taylor.</p>\n",
    "    <p>On prend $a = 0.5$, $b_0 = 1b$ et $b = 2\\gamma_{k-1}$. On cherche le premier entier $l$ non-négatif tel que:</p>\n",
    "    $$f_2(\\omega^+(ba^l)) \\leq f_2(\\omega^k) + \\langle\\nabla_{f_2}(\\omega^k),\\,\\omega^+(ba^l)-\\omega^k\\rangle + \\frac{1}{2ba^l}\\|\\omega^k - \\omega^+(ba^l)\\|^2$$\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    On peut utiliser un seuillage pour la valeur de fonction objectif évaluée dans une itération comme test d'arrêt.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value minimal of the objective function is: 0.692565193505\n",
      "Done in 0.072s, number of iterations: 8\n",
      "[-0.05716261  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.004657\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.00538332  0.          0.          0.01859929  0.          0.01859929\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "def objective_proximal(w_, X, y, rho):\n",
    "    \"\"\"\n",
    "    X: matrix of size n*(p+1)\n",
    "    y: vector of size n\n",
    "    w0: real number\n",
    "    w: vector of size p\n",
    "    \"\"\"\n",
    "    # Initialize elementary intermediate variables;\n",
    "    n, p = X.shape\n",
    "    w = w_[1:]\n",
    "    y_x = np.array([y[i] * X[i, :] for i in range(n)])\n",
    "    yx_w = np.array([np.sum(y_x[i, :]*w_) for i in range(n)])\n",
    "    exp_neg_yxw_1 = np.array([np.exp(-yx_w[i]) for i in range(n)]) + 1\n",
    "    \n",
    "    # Compute function value\n",
    "    val = np.mean(np.log(exp_neg_yxw_1)) + rho*np.sum(np.fabs(w)) \n",
    "    return val\n",
    "\n",
    "def f(w_, X, y, return_grad=True):\n",
    "    \"\"\"\n",
    "    X: matrix of size n*(p+1)\n",
    "    y: vector of size n\n",
    "    w0: real number\n",
    "    w: vector of size p\n",
    "    \"\"\"\n",
    "    # Initialize elementary intermediate variables;\n",
    "    n, p = X.shape\n",
    "    w = w_[1:]\n",
    "    y_x = np.array([y[i] * X[i, :] for i in range(n)])\n",
    "    yx_w = np.array([np.sum(y_x[i, :]*w_) for i in range(n)])\n",
    "    exp_yxw_1 = np.array([np.exp(yx_w[i]) for i in range(n)]) + 1\n",
    "    exp_neg_yxw_1 = np.array([np.exp(-yx_w[i]) for i in range(n)]) + 1\n",
    "    \n",
    "    # Compute function value\n",
    "    val = np.mean(np.log(exp_neg_yxw_1))\n",
    "    \n",
    "    if return_grad == False:\n",
    "        return val\n",
    "    else:\n",
    "        # Compute gradient\n",
    "        grad = np.mean(-np.array([y_x[i]/exp_yxw_1[i] for i in range(n)]), axis=0)\n",
    "        return val, grad\n",
    "    \n",
    "def Soft_Threshold(w, rho):\n",
    "    w_ = np.zeros_like(w)\n",
    "    w_[w > rho] = w[w > rho] - rho\n",
    "    w_[w < -rho] = w[w < -rho] + rho\n",
    "    w_[0] = w[0]\n",
    "    return w_\n",
    "\n",
    "def minimize_prox_grad_Taylor(func, f, w_, X, y, rho, a, b, tol=1e-10, max_iter=500):\n",
    "    n, p = X.shape\n",
    "    val = func(w_, X, y, rho)\n",
    "    val_f, grad_f = f(w_, X, y)\n",
    "    gamma = b / 2.\n",
    "    delta_val = tol*2\n",
    "    cnt = 0\n",
    "    while (delta_val > tol and cnt < max_iter):\n",
    "        gamma = 2*gamma\n",
    "        w_new = Soft_Threshold(w_ - gamma*grad_f, gamma*rho)\n",
    "        val_f_ = f(w_new, X, y, return_grad=False)\n",
    "        #while (val_f_ > val_f + beta*np.sum(grad_f*(w_new - w_))):\n",
    "        while (val_f_ > val_f + np.sum(grad_f*(w_new-w_)) + np.sum((w_new-w_)**2)/gamma):\n",
    "            #print val_\n",
    "            gamma = gamma*a\n",
    "            w_new = Soft_Threshold(w_ - gamma*grad_f, gamma*rho)\n",
    "            val_f_ = f(w_new, X, y, return_grad=False)\n",
    "        w_ = w_new\n",
    "        val_f, grad_f = f(w_, X, y)\n",
    "        val_ = func(w_, X, y, rho)\n",
    "        delta_val = val - val_\n",
    "        val = val_\n",
    "        cnt = cnt + 1\n",
    "    return func(w_, X, y, rho), w_, cnt\n",
    "\n",
    "t0 = time()\n",
    "rho = 0.1\n",
    "a = 0.5\n",
    "b = 1\n",
    "val_pgls, w_pgls, cnt_pgls  = minimize_prox_grad_Taylor(objective_proximal, f, 0.3*np.ones(p+1), X, y, rho, a, b, tol=1e-8, max_iter=500)\n",
    "print \"The value minimal of the objective function is: %0.12f\" % val_pgls\n",
    "t_pgls = time()-t0\n",
    "print \"Done in %0.3fs, number of iterations: %d\" % (t_pgls, cnt_pgls)\n",
    "print w_pgls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value minimal of the objective function is: 0.692577339566\n",
      "Done in 0.178s, number of iterations: 21\n",
      "[-0.0567545   0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.01092454  0.          0.          0.0130465   0.          0.0130465   0.        ]\n"
     ]
    }
   ],
   "source": [
    "def objective_proximal(w_, X, y, rho, return_grad=True):\n",
    "    \"\"\"\n",
    "    X: matrix of size n*(p+1)\n",
    "    y: vector of size n\n",
    "    w0: real number\n",
    "    w: vector of size p\n",
    "    \"\"\"\n",
    "    # Initialize elementary intermediate variables;\n",
    "    n, p = X.shape\n",
    "    w = w_[1:]\n",
    "    y_x = np.array([y[i] * X[i, :] for i in range(n)])\n",
    "    yx_w = np.array([np.sum(y_x[i, :]*w_) for i in range(n)])\n",
    "    exp_yxw_1 = np.array([np.exp(yx_w[i]) for i in range(n)]) + 1\n",
    "    exp_neg_yxw_1 = np.array([np.exp(-yx_w[i]) for i in range(n)]) + 1\n",
    "    \n",
    "    # Compute function value\n",
    "    val = np.mean(np.log(exp_neg_yxw_1)) + rho*np.sum(np.fabs(w)) \n",
    "    \n",
    "    if return_grad == False:\n",
    "        return val\n",
    "    else:\n",
    "        # Compute gradient\n",
    "        grad = np.mean(-np.array([y_x[i]/exp_yxw_1[i] for i in range(n)]), axis=0)\n",
    "        return val, grad\n",
    "    \n",
    "def Soft_Threshold(w, rho):\n",
    "    w_ = np.zeros_like(w)\n",
    "    w_[w > rho] = w[w > rho] - rho\n",
    "    w_[w < -rho] = w[w < -rho] + rho\n",
    "    w_[0] = w[0]\n",
    "    return w_\n",
    "\n",
    "def minimize_prox_grad_Armijo(func, w_, X, y, rho, a, b, beta, tol=1e-10, max_iter=500):\n",
    "    val, grad = func(w_, X, y, rho)\n",
    "    gamma = b / 2.\n",
    "    delta_val = tol*2\n",
    "    cnt = 0\n",
    "    while (delta_val > tol and cnt < max_iter):\n",
    "        gamma = 2*gamma\n",
    "        w_new = Soft_Threshold(w_ - gamma*grad, rho)\n",
    "        val_ = func(w_new, X, y, rho, return_grad=False)\n",
    "        while (val_ > val + beta*np.sum(grad*(w_new - w_))):\n",
    "            gamma = gamma*a\n",
    "            w_new = Soft_Threshold(w_ - gamma*grad, rho)\n",
    "            val_ = func(w_new, X, y, rho, return_grad=False)\n",
    "        w_ = w_new\n",
    "        val_, grad = func(w_, X, y, rho)\n",
    "        delta_val = val - val_\n",
    "        val = val_\n",
    "        cnt = cnt + 1\n",
    "    return val, w_, cnt\n",
    "\n",
    "t0 = time()\n",
    "rho = 0.1\n",
    "a = 0.7\n",
    "b = 1\n",
    "beta = 0.5\n",
    "val_pgls, w_pgls, cnt_pgls  = minimize_prox_grad_Armijo(objective_proximal, 0.3*np.ones(p+1), X, y, rho, a, b, beta, tol=1e-6, max_iter=500)\n",
    "print \"The value minimal of the objective function is: %0.12f\" % val_pgls\n",
    "t_pgls = time()-t0\n",
    "print \"Done in %0.3fs, number of iterations: %d\" % (t_pgls, cnt_pgls)\n",
    "print w_pgls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3: Comparaison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Question 3.1}\\quad\\text{Comparer les propriétés des deux problèmes d’optimisation.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p>1. Toutes les deux fonctions objectifs sont convexes, laquelle de régularisation de Tikhonov est différentible, l'autre n'est pas différentiable.</p>\n",
    "    <p>2. Selon les deux $\\omega$ qu'on obtient, la régularisation de Tiknonov utilise tous les variables explicatives, la régularisation pour la parcimoine en utilise une partie.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Question 3.2}\\quad\\text{Comparer les solutions obtenues avec les deux types de régularisation.}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chance level is: 0.514286\n",
      "The score by Newton method with line search is: 0.685714\n",
      "The score by proximal gradient method with line search is: 0.561905\n",
      "------------------------------------------------------------\n",
      "Classification report for Newton method\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.65      0.84      0.73       108\n",
      "        1.0       0.76      0.52      0.62       102\n",
      "\n",
      "avg / total       0.70      0.69      0.68       210\n",
      "\n",
      "------------------------------------------------------------\n",
      "Classification report for proximal gradient method\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.54      1.00      0.70       108\n",
      "        1.0       1.00      0.10      0.18       102\n",
      "\n",
      "avg / total       0.76      0.56      0.45       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_nls = np.sign(X.dot(w_nls))\n",
    "y_pred_pgls = np.sign(X.dot(w_pgls))\n",
    "print \"The chance level is: %f\" % max(np.mean(y == 1), 1-np.mean(y == 1))\n",
    "print \"The score by Newton method with line search is: %f\" % np.mean(y == y_pred_nls)\n",
    "print \"The score by proximal gradient method with line search is: %f\" % np.mean(y == y_pred_pgls)\n",
    "\n",
    "print \"-\"*60\n",
    "print \"Classification report for Newton method\"\n",
    "print classification_report(y, y_pred_nls)\n",
    "print \"-\"*60\n",
    "print \"Classification report for proximal gradient method\"\n",
    "print classification_report(y, y_pred_pgls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p>En comparant les scores et les rapports de classification:</p>\n",
    "    <p>1. Le score obtenu par la méthode de Newton est meilleur que celui de la méthode de gradient proximal.</p>\n",
    "    <p>2. Selon le f1-score, la méthode de Newton est aussi meilleur.</p>\n",
    "    <p>3. Dans la méthode de gradient proximal, la «precision» pour class 1 est 1.0, de plus, la «recall» est 0.1. On peut conclure que cette méthode avandage la class 1.</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
