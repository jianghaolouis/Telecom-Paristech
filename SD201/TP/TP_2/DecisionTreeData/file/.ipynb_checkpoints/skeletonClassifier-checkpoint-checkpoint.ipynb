{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise on Decision Trees\n",
    "\n",
    "The iris dataset has been partitioned in two parts:\n",
    "\n",
    "1. the training set containing 50 records from which we would like to build the decision tree. This consists of an array called *training_data*, containing the data and an array called *training_class* specifying the class (i.e. a value in {0,1,2}) for each record in the training set. \n",
    "2. the test set containing 100 records that we shall use to evaluate our decision tree. It consists of an array called *test_data* containing the data and *test_class* specifying the class for each record in the training set. \n",
    "\n",
    "All arrays mentioned above are *numpy.ndarray* arrays (see additional notes at the end of this notebook). In particular *training_class[i]* specifies the class of *training_data[i]*, while *test_class[i]* specifies the class of *test_data[i]* for any record *i* in the data.\n",
    "\n",
    "In order to solve this exercise you should properly fill the missing parts in this skeleton code. In order to solve the more difficult exercise you can change the code as you wish, without changing the code specifying the training set or any of the seeds of the random number generators (e.g. RandomState(130)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e26935a6e359>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msix\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pydot'"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.externals.six import StringIO\n",
    "import pydot\n",
    "import numpy as np\n",
    "import random\n",
    "from numpy.random import RandomState\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "#load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "\n",
    "#splitting dataset in training and test sets\n",
    "random.seed(1118)\n",
    "size_tr=50\n",
    "n2=3\n",
    "f = range(0,100)\n",
    "g = range(0,50)\n",
    "random.shuffle(f)\n",
    "random.shuffle(g)\n",
    "training_data=[]\n",
    "training_class= []\n",
    "test_data= []\n",
    "test_class= []\n",
    "for i in range(0,size_tr-n2):\n",
    "    training_data.append(iris.data[f[i]])\n",
    "    training_class.append(iris.target[f[i]])    \n",
    "for i in range(0,n2):\n",
    "    training_data.append(iris.data[100+g[i]])\n",
    "    training_class.append(iris.target[100+g[i]])    \n",
    "for i in range(size_tr-n2,100):\n",
    "    test_data.append(iris.data[f[i]])\n",
    "    test_class.append(iris.target[f[i]])    \n",
    "for i in range(n2,50):\n",
    "    test_data.append(iris.data[100+g[i]])\n",
    "    test_class.append(iris.target[100+g[i]])    \n",
    "training_data=np.array(training_data)\n",
    "training_class=np.array(training_class)\n",
    "test_data=np.array(test_data)\n",
    "test_class=np.array(test_class)\n",
    "\n",
    "\n",
    "#building the classifier (the option random_state=RandomState(130) makes the algorithm deterministic)\n",
    "clf = tree.DecisionTreeClassifier(criterion='gini', random_state=RandomState(130))\n",
    "clf = clf.fit(training_data, training_class)\n",
    "\n",
    "#print the decision tree in a pdf file\n",
    "from sklearn.externals.six import StringIO  \n",
    "import pydot \n",
    "dot_data = StringIO() \n",
    "tree.export_graphviz(clf, out_file=dot_data) \n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue()) \n",
    "graph.write_pdf(\"iris.pdf\") \n",
    "\n",
    "# the following code evaluates the decision tree on the test set and compute a confidence interval for \n",
    "# the accuracy. You should create a list a, where a[i]=1 if the ith record test_data[i] has been classified \n",
    "# correctly and 0 otherwise. Remember, a.append(1) add one more element to the list with value = 1.\n",
    "a=[]\n",
    "for i in range(0,len(test_data)):\n",
    "# fill properly this missing part\n",
    "    \n",
    "    \n",
    "#The following code computes a confidence interval for the accuracy. The first argument is the confidence, \n",
    "#e.g. 0.9, while the second argument of stats.norm.interval is the mean of the list a. Fill properly those\n",
    "# parts.   \n",
    "    CI = stats.norm.interval(0.9,0.2,scale=stats.sem(a))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional Notes on numpy.ndarray arrays**\n",
    "\n",
    "Training data and test data are bidimensional numpy.ndarray arrays. The notation for them is slightly different than in usual bidimensional arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#notes on numpy.ndarray\n",
    "b = np.arange(15).reshape(3, 5) # create a bidim array with 3 rows and 5 columns\n",
    "b[2][4] #value in row 2 and column 4 of b (first row has index 0)\n",
    "b[[1,2]] #extract rows 1 and 2 \n",
    "b[1:3] #another way of extracting rows 1,2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
